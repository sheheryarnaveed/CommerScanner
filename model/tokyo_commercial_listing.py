# -*- coding: utf-8 -*-
"""Tokyo_Commercial_Listing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16QUmmbj2cH4pMLx-9U7KJB0okyg6X8KV
"""

import sys
!pip install geocoder
!pip install geopy
!pip install wget
!pip install mtranslate

import numpy as np # library to handle data in a vectorized manner
from mtranslate import translate

import pandas as pd # library for data analsysis
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)

import json # library to handle JSON files

#!conda install -c conda-forge geopy --yes # uncomment this line if you haven't completed the Foursquare API lab
from geopy.geocoders import Nominatim # convert an address into latitude and longitude values

import requests # library to handle requests
from pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe

# Matplotlib and associated plotting modules
import matplotlib.cm as cm
import matplotlib.colors as colors


# import k-means from clustering stage
from sklearn.cluster import KMeans

#!conda install -c conda-forge folium=0.5.0 --yes # uncomment this line if you haven't completed the Foursquare API lab
import folium # map rendering library

print('Libraries imported.')

cols = ['User_ID', 'Venue_ID', 'Category_ID', 'Category_Name', 'Latitude', 'Longitude', "Time Zone(off. mins)", "UTC Time"] 
df = pd.read_csv('../data/dataset_TSMC2014_TKY.txt', sep='\t', lineterminator='\n', encoding = "ISO-8859-1")
df.columns=cols
df.reset_index() 

df.head(5)

# define the dataframe columns
column_names = ['Venue_ID', 'Category_Name', 'Visitor_Count', 'Latitude', 'Longitude'] 

# instantiate the dataframe
venue_data = pd.DataFrame(columns=column_names)

v = df.groupby('Venue_ID')[['User_ID']].transform('count')
df['Visitor_Count'] = v.User_ID
g = df.drop_duplicates(subset=['Venue_ID', 'Visitor_Count'])
g = g[:2000] # We are only interested in the first 2000 entries
g.head(5)

# Checking if we have grouped successfully
print('The dataframe has {} venues with total of {} visitors.'.format(
        len(g['Venue_ID'].unique()),
        sum(g['Visitor_Count'])
    )
)
g.shape

venue_data = g.drop(['User_ID', 'Category_ID', "Time Zone(off. mins)", "UTC Time"], axis=1)
venue_data.head(5)

#Sorting the data so we get the top visited place first
sorted_venue_data = venue_data.sort_values(['Visitor_Count'], axis=0, ascending=False, inplace=False, kind='quicksort', na_position='last')

sorted_venue_data_2 = sorted_venue_data.copy()
sorted_venue_data.head(5)

#Grouping by category names and then sorting
v = sorted_venue_data.groupby('Category_Name')[['Visitor_Count']].transform('sum')
sorted_venue_data['Visitor_Count'] = v.Visitor_Count
cat_df = sorted_venue_data.drop_duplicates(subset=['Category_Name', 'Visitor_Count'])


final_data = cat_df.sort_values(['Visitor_Count'], axis=0, ascending=False, inplace=False, kind='quicksort', na_position='last')
final_data.head(5)

categories_of_interest = ['Food & Drink Shop', 'Electronics Store', 'Coffee Shop', 'Restaurant', 'Arts & Crafts Store', 'Gastropub', 
                  'Mobile Phone Shop', 'Café', 'Automative Shop', 'American Restaurant', 'Food & Drink Shop', 'Burger Joint',
                  'Mexican Restaurant', 'Sandwich Place', 'Clothing Store', 'Ice Cream Shop', 'Pizza Place', 'Jewelry Store', 
                  'Soup Place', 'Tattoo Parlor', 'Deli / Bodega', 'Diner', 'Salon / Barbershop', 'Laundry Service', 'Bar', 
                  'Gym / Fitness Center', 'Hotel', 'Music Venue', 'BBQ Joint', 'Bookstore', 'Drugstore / Pharmacy',
                  'Sporting Goods Shop', 'Bakery', 'Fast Food Restaurant', 'Chinese Restaurant', 'Theater', 'Movie Theater', 
                  'Sushi Restaurant', 'Miscellaneous Shop', 'French Restaurant', 'Seafood Restaurant', 'Fried Chicken Joint', 
                  'Italian Restaurant', 'Toy / Game Store', 'Vegetarian / Vegan Restaurant', 'Donut Shop', 'German Restaurant', 
                  'Bowling Alley', 'Beer Garden', 'Candy Store', 'Bagel Shop', 'Cuban Restaurant', 'Cupcake Shop', 
                  'Breakfast Spot', 'Hardware Store', 'Japanese Restaurant',  'Latin American Restaurant', 'Spanish Restaurant',
                  'Spa / Massage', 'Middle Eastern Restaurant', 'Malaysian Restaurant', 'Record Shop', 'Wings Joint', 
                  'Gas Station / Garage', 'Asian Restaurant', 'Burrito Place', 'Thai Restaurant', 'Salad Place', 
                  'Ramen /  Noodle House', 'Automotive Shop', 'Convenience Store', 'Tea Room',  'Indian Restaurant', 
                  'Thrift / Vintage Store', 'Paper / Office Supplies Store', 'Cosmetics Shop', 'Southern / Soul Food Restaurant',
                  'Smoke Shop', 'Snack Place', 'Furniture / Home Store', 'Caribbean Restaurant', 'Video Game Store', 'Steakhouse',
                  'Greek Restaurant', 'Dumpling Restaurant', 'Mediterranean Restaurant', 'African Restaurant', 'Taco Place', 
                  'Jewelry Store', 'Hot Dog Joint', 'South American Restaurant', 'Winery']
df_filtered = final_data[final_data['Category_Name'].isin(categories_of_interest)] 
df_filtered.sort_values(['Visitor_Count'], axis=0, ascending=False, inplace=False, kind='quicksort', na_position='last')
df_filtered.head(5)

df_filtered.shape

maxVisited = df_filtered['Category_Name'].iloc[0]
print(maxVisited)

# We need to find the number of each of the commercial type within 4 km of a given coordinate. So we use the sorted_venue_data df again  because a commercial shop category maybe available in multiple locations
# Remember to remove the unwanted categories from it

categories_of_interest = ['Food & Drink Shop', 'Electronics Store', 'Coffee Shop', 'Restaurant', 'Arts & Crafts Store', 'Gastropub', 
                  'Mobile Phone Shop', 'Café', 'Automative Shop', 'American Restaurant', 'Food & Drink Shop', 'Burger Joint',
                  'Mexican Restaurant', 'Sandwich Place', 'Clothing Store', 'Ice Cream Shop', 'Pizza Place', 'Jewelry Store', 
                  'Soup Place', 'Tattoo Parlor', 'Deli / Bodega', 'Diner', 'Salon / Barbershop', 'Laundry Service', 'Bar', 
                  'Gym / Fitness Center', 'Hotel', 'Music Venue', 'BBQ Joint', 'Bookstore', 'Drugstore / Pharmacy',
                  'Sporting Goods Shop', 'Bakery', 'Fast Food Restaurant', 'Chinese Restaurant', 'Theater', 'Movie Theater', 
                  'Sushi Restaurant', 'Miscellaneous Shop', 'French Restaurant', 'Seafood Restaurant', 'Fried Chicken Joint', 
                  'Italian Restaurant', 'Toy / Game Store', 'Vegetarian / Vegan Restaurant', 'Donut Shop', 'German Restaurant', 
                  'Bowling Alley', 'Beer Garden', 'Candy Store', 'Bagel Shop', 'Cuban Restaurant', 'Cupcake Shop', 
                  'Breakfast Spot', 'Hardware Store', 'Japanese Restaurant',  'Latin American Restaurant', 'Spanish Restaurant',
                  'Spa / Massage', 'Middle Eastern Restaurant', 'Malaysian Restaurant', 'Record Shop', 'Wings Joint', 
                  'Gas Station / Garage', 'Asian Restaurant', 'Burrito Place', 'Thai Restaurant', 'Salad Place', 
                  'Ramen /  Noodle House', 'Automotive Shop', 'Convenience Store', 'Tea Room',  'Indian Restaurant', 
                  'Thrift / Vintage Store', 'Paper / Office Supplies Store', 'Cosmetics Shop', 'Southern / Soul Food Restaurant',
                  'Smoke Shop', 'Snack Place', 'Furniture / Home Store', 'Caribbean Restaurant', 'Video Game Store', 'Steakhouse',
                  'Greek Restaurant', 'Dumpling Restaurant', 'Mediterranean Restaurant', 'African Restaurant', 'Taco Place', 
                  'Jewelry Store', 'Hot Dog Joint', 'South American Restaurant', 'Winery']
df_filtered_final = sorted_venue_data_2[sorted_venue_data_2['Category_Name'].isin(categories_of_interest)] 
# df_filtered_final = sorted_venue_data_2
df_filtered_final.sort_values(['Visitor_Count'], axis=0, ascending=False, inplace=False, kind='quicksort', na_position='last')
df_filtered_final.head(5)

# Here we can see that multiple electornic stores at different locations.

df_filtered_final.shape

# Credits to gihub.com/SalimT for these functions

from math import cos, asin, sqrt
nearNeighborhoods = []

# Calculates the distance between two coordinates
def distance(lat1, lon1, lat2, lon2):
    p = 0.017453292519943295
    a = 0.5 - cos((lat2-lat1)*p)/2 + cos(lat1*p)*cos(lat2*p) * (1-cos((lon2-lon1)*p)) / 2
    return 12742 * asin(sqrt(a))

# Finding the closest venue having less than the most number of shops to the target venue within the sorted list which has the most number of shops
def closest(data, v): 
    return min(data, key=lambda p: distance(float(v[0]),float(v[1]),float(p[0][0]),float(p[0][1])) if p[0] not in nearNeighborhoods else 9999)

import math as Math
def pointInCircle(lat0, lon0, r, lat, lon):  
    C = 40075.04                                               # Earth circumference
    A = 360*r/C                                                # semi-minor in north-south direction 
    B = A/Math.cos(Math.radians(float(lat0)));                 # semi-major in east-west direction
    return Math.pow((float(lat)-float(lat0))/A, 2) + Math.pow((float(lon)-float(lon0))/B, 2) < 1;

# For each coordinate we want to find the number of Electronic Store present within three kms
radius = 3
mostVisitedCommercialPlace = {}
visited = []

id = 0
for index, row in df_filtered_final.iterrows():
    
    c = [row['Latitude'], row['Longitude']]
    coords = tuple(c)
    if coords in visited:
        continue
    visited.append(coords)

    storeCount = {}
    for i, r in df_filtered_final.iterrows():
        temp_coord = tuple([r['Latitude'], row['Longitude']])
        venue_type = r['Category_Name']
        
        if pointInCircle(coords[0], coords[1], radius, temp_coord[0], temp_coord[1]) and temp_coord not in visited:
            
            visited.append(temp_coord)
            if venue_type not in storeCount:
                storeCount[venue_type] = 1
            else:
                storeCount[venue_type] = storeCount.get(venue_type)+1

        if maxVisited not in storeCount:
            mostVisitedCommercialPlace[coords] = 0
        else: 
            mostVisitedCommercialPlace[coords] = storeCount.get(maxVisited)
    id+=1
    print(id)       

sorted_dict = sorted(mostVisitedCommercialPlace.items(), key=lambda x: x[1], reverse=True)
mostShopCoord = list(sorted_dict)[0][0]

i = 0
for c in sorted_dict:
    print(c[0], ":", c[1])
    i+=1
    if(i==30):
        break

print("Coordinate that has the given specific shop the most: ", mostShopCoord, " which is: ", list(sorted_dict)[0][1])

del sorted_dict[0] # Deleting for the sake of finding the coords most similar to this

CLIENT_ID = 'I5AKKEVY2J2HUAM0XSAKK0KVHD3WSSTXPS2055CJORRLE3UL' # your Foursquare ID
CLIENT_SECRET = 'TS4KJOJSMF5TTUBUXVNKLYMHKIX3NCLWIUL1QEPEZM0NIXBP' # your Foursquare Secret
VERSION = '20180604'
LIMIT = 30
print('Your credentails:')
print('CLIENT_ID: ' + CLIENT_ID)
print('CLIENT_SECRET:' + CLIENT_SECRET)

neighborhoods = {}
findNumOfPlaces = 2

# url = 'https://api.foursquare.com/v2/venues/search?client_id={}&client_secret={}&ll={},{}&v={}&query={}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET, latitude, longitude, VERSION, search_query, radius, LIMIT)


centerNeighborhoodData = requests.get('https://api.foursquare.com/v2/venues/search?&client_id={}&client_secret={}&v={}&ll={},{}&limit=1'.format(CLIENT_ID,CLIENT_SECRET, VERSION, float(mostShopCoord[0]), float(mostShopCoord[1]))).json()

centerNeighborhood = centerNeighborhoodData['response']['venues'][0]['location']['formattedAddress']

while len(neighborhoods) != findNumOfPlaces:
    nearNeighborhoods.append(closest(list(sorted_dict), mostShopCoord)[0])
    lat = nearNeighborhoods[-1][0]
    lng = nearNeighborhoods[-1][1]
    url = 'https://api.foursquare.com/v2/venues/search?&client_id={}&client_secret={}&v={}&ll={},{}&limit=1'.format(CLIENT_ID,CLIENT_SECRET, VERSION,lat,lng)
    results=requests.get(url).json()
    
    try:
        neighborhoods[results['response']['venues'][0]['location']['neighborhood']] = tuple([lat,lng])
    except:
        continue

translated_neighborhoods = []
for neighbor in neighborhoods:
  eng_name = translate(neighbor, "en", "auto")
  translated_neighborhoods.append(end_name)
  print(eng_name)

import folium

mapit = folium.Map( location=[35.70, 139.78], zoom_start=15)
latlon = []
neighboorhoodNames = []

for name, coords in translated_neighborhoods.items():
    latlon.append(tuple([float(coords[0]), float(coords[1])]))
    neighboorhoodNames.append(name)


# shop's coordinates with the most number of the given shop
folium.CircleMarker(
        [mostShopCoord[0], mostShopCoord[1]],
        radius=4,
        color='#ff0000',
        fill=True,
        fill_color='#ff0000',
        popup=folium.Popup('{}, Tokyo'.format(centerNeighborhood), parse_html=True),
        parse_html=False,
        fill_opacity=0.8).add_to(mapit)


# label the potential neighborhoods
for c, n in zip(latlon, neighboorhoodNames):
    label = '{}, Tokyo'.format(n)
    label = folium.Popup(label, parse_html=True)

    folium.Marker(location=[ c[0], c[1] ], popup=label ).add_to( mapit )

mapit

